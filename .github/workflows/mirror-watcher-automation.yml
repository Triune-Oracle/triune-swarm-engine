name: 🔍 MirrorWatcherAI Automation

on:
  schedule:
    # Daily execution at 06:00 UTC (starting 2025-08-19)
    - cron: '0 6 * * *'
  
  workflow_dispatch:
    # Manual trigger for testing and immediate execution
    inputs:
      analysis_type:
        description: 'Type of analysis to perform'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - repositories_only
          - security_focus
          - health_check
      
      target_repositories:
        description: 'Specific repositories to analyze (comma-separated)'
        required: false
        type: string
      
      force_sync:
        description: 'Force synchronization with all Triune systems'
        required: false
        default: false
        type: boolean

# Prevent overlapping workflow runs
concurrency:
  group: mirror-watcher-automation
  cancel-in-progress: false

# Workflow permissions for secure operation
permissions:
  contents: read          # Read repository contents
  actions: read          # Read workflow artifacts
  checks: write          # Write check status
  issues: write          # Create issues for alerts
  pull-requests: read    # Read PR information
  security-events: write # Write security events
  id-token: write        # For attestation creation

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  ANALYSIS_TIMEOUT: '1800'  # 30 minutes
  STEP_TIMEOUT: '300'       # 5 minutes per step
  HEALTH_CHECK_TIMEOUT: '60' # 1 minute for health checks
  SYNC_TIMEOUT: '900'       # 15 minutes for ecosystem sync
  ARTIFACT_RETENTION_DAYS: 90
  MAX_RETRIES: 3
  RETRY_DELAY: 30           # seconds between retries

jobs:
  mirror-analysis:
    name: 🔍 Mirror Analysis & Attestation
    runs-on: ubuntu-latest
    timeout-minutes: 35  # Slightly more than ANALYSIS_TIMEOUT for buffer
    
    # Enhanced job strategy for error resilience
    strategy:
      fail-fast: false
      max-parallel: 1
    
    outputs:
      analysis-id: ${{ steps.analysis.outputs.analysis-id }}
      execution-status: ${{ steps.analysis.outputs.status }}
      repositories-analyzed: ${{ steps.analysis.outputs.repositories-count }}
      health-score: ${{ steps.analysis.outputs.health-score }}
      security-status: ${{ steps.analysis.outputs.security-status }}
      error-details: ${{ steps.error-handler.outputs.error-summary }}
      start-time: ${{ steps.workflow-init.outputs.start-time }}
      end-time: ${{ steps.workflow-finalize.outputs.end-time }}
    
    steps:
      - name: 🚀 Workflow Initialization
        id: workflow-init
        run: |
          echo "::group::Workflow Initialization"
          START_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "start-time=${START_TIME}" >> $GITHUB_OUTPUT
          echo "🚀 MirrorWatcherAI workflow started at ${START_TIME}"
          echo "📋 Trigger: ${{ github.event_name }}"
          echo "📂 Repository: ${{ github.repository }}"
          echo "🔄 Run ID: ${{ github.run_id }}"
          echo "::endgroup::"
      
      - name: 🚀 Checkout Repository
        uses: actions/checkout@v4
        timeout-minutes: 2
        with:
          fetch-depth: 0  # Full history for comprehensive analysis
      
      - name: 🔍 Environment Validation
        id: env-validation
        timeout-minutes: 2
        run: |
          echo "::group::Environment Validation"
          
          # Track validation status
          VALIDATION_ERRORS=0
          
          # Check required secrets
          echo "🔐 Validating secrets configuration..."
          if [ -z "${{ secrets.REPO_SYNC_TOKEN }}" ]; then
            echo "::warning::REPO_SYNC_TOKEN not configured - some analysis features may be limited"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
          else
            echo "✅ REPO_SYNC_TOKEN configured"
          fi
          
          if [ -z "${{ secrets.SHADOWSCROLLS_ENDPOINT }}" ] || [ -z "${{ secrets.SHADOWSCROLLS_API_KEY }}" ]; then
            echo "::warning::ShadowScrolls credentials not fully configured - attestation may fail"
            VALIDATION_ERRORS=$((VALIDATION_ERRORS + 1))
          else
            echo "✅ ShadowScrolls configuration found"
          fi
          
          # Validate environment settings
          echo "🌍 Validating environment settings..."
          echo "Python version: ${{ env.PYTHON_VERSION }}"
          echo "Analysis timeout: ${{ env.ANALYSIS_TIMEOUT }}s"
          echo "Step timeout: ${{ env.STEP_TIMEOUT }}s"
          echo "Max retries: ${{ env.MAX_RETRIES }}"
          
          # Set validation status
          if [ $VALIDATION_ERRORS -eq 0 ]; then
            echo "validation-status=pass" >> $GITHUB_OUTPUT
            echo "✅ Environment validation passed"
          else
            echo "validation-status=warnings" >> $GITHUB_OUTPUT
            echo "⚠️ Environment validation completed with ${VALIDATION_ERRORS} warnings"
          fi
          
          echo "validation-errors=${VALIDATION_ERRORS}" >> $GITHUB_OUTPUT
          echo "::endgroup::"
      
      - name: 🐍 Setup Python Environment
        uses: actions/setup-python@v5
        timeout-minutes: 3
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: requirements.txt
      
      - name: 📦 Install Dependencies
        id: install-deps
        timeout-minutes: 5
        run: |
          echo "::group::Dependency Installation"
          
          # Install with retries
          RETRY_COUNT=0
          MAX_RETRIES=${{ env.MAX_RETRIES }}
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "📦 Installing dependencies (attempt $((RETRY_COUNT + 1))/${MAX_RETRIES})"
            
            if python -m pip install --upgrade pip && \
               pip install -r requirements.txt && \
               pip install aiohttp aiosqlite GitPython requests beautifulsoup4 lxml; then
              echo "✅ Dependencies installed successfully"
              echo "install-status=success" >> $GITHUB_OUTPUT
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "⚠️ Installation failed, retrying in ${{ env.RETRY_DELAY }} seconds..."
                sleep ${{ env.RETRY_DELAY }}
              else
                echo "::error::❌ Failed to install dependencies after ${MAX_RETRIES} attempts"
                echo "install-status=failed" >> $GITHUB_OUTPUT
                exit 1
              fi
            fi
          done
          
          # Verify installations
          echo "🔍 Verifying key packages..."
          python -c "import aiohttp, aiosqlite, git, requests; print('✅ Core packages verified')"
          
          echo "::endgroup::"
      
      - name: 🔧 Configure Environment
        id: env-config
        timeout-minutes: 2
        env:
          REPO_SYNC_TOKEN: ${{ secrets.REPO_SYNC_TOKEN }}
          SHADOWSCROLLS_ENDPOINT: ${{ secrets.SHADOWSCROLLS_ENDPOINT }}
          SHADOWSCROLLS_API_KEY: ${{ secrets.SHADOWSCROLLS_API_KEY }}
          LEGIO_COGNITO_API_KEY: ${{ secrets.LEGIO_COGNITO_API_KEY }}
          TRIUMVIRATE_MONITOR_API_KEY: ${{ secrets.TRIUMVIRATE_MONITOR_API_KEY }}
          SWARM_ENGINE_API_KEY: ${{ secrets.SWARM_ENGINE_API_KEY }}
        run: |
          echo "::group::Environment Configuration"
          
          # Create environment configuration with fallbacks
          echo "REPO_SYNC_TOKEN=${REPO_SYNC_TOKEN:-}" >> $GITHUB_ENV
          echo "SHADOWSCROLLS_ENDPOINT=${SHADOWSCROLLS_ENDPOINT:-https://shadowscrolls.local}" >> $GITHUB_ENV
          echo "SHADOWSCROLLS_API_KEY=${SHADOWSCROLLS_API_KEY:-}" >> $GITHUB_ENV
          echo "LEGIO_COGNITO_API_KEY=${LEGIO_COGNITO_API_KEY:-}" >> $GITHUB_ENV
          echo "TRIUMVIRATE_MONITOR_API_KEY=${TRIUMVIRATE_MONITOR_API_KEY:-}" >> $GITHUB_ENV
          echo "SWARM_ENGINE_API_KEY=${SWARM_ENGINE_API_KEY:-}" >> $GITHUB_ENV
          
          # GitHub Actions specific environment
          echo "GITHUB_ACTIONS=true" >> $GITHUB_ENV
          echo "MIRROR_WATCHER_LOG_FILE=mirror_watcher_ai.log" >> $GITHUB_ENV
          echo "MIRROR_WATCHER_MODE=production" >> $GITHUB_ENV
          echo "ANALYSIS_TIMEOUT=${{ env.ANALYSIS_TIMEOUT }}" >> $GITHUB_ENV
          
          # Create required directories with proper permissions
          mkdir -p artifacts reports logs .shadowscrolls/attestations
          chmod 755 artifacts reports logs .shadowscrolls .shadowscrolls/attestations
          
          # Create default config files if they don't exist
          if [ ! -f ".env.mirror_watcher" ]; then
            cat > .env.mirror_watcher << EOF
          # MirrorWatcher Configuration (GitHub Actions)
          MIRROR_WATCHER_MODE=production
          ANALYSIS_TIMEOUT=${{ env.ANALYSIS_TIMEOUT }}
          LOG_LEVEL=INFO
          GITHUB_ACTIONS=true
          EOF
          fi
          
          echo "config-status=success" >> $GITHUB_OUTPUT
          echo "✅ Environment configured successfully"
          echo "📂 Created directories: artifacts, reports, logs, .shadowscrolls/attestations"
          echo "::endgroup::"
      
      - name: 🔍 System Health Check
        id: health-check
        timeout-minutes: 2
        run: |
          echo "::group::System Health Check"
          
          # Run comprehensive health check with timeout
          timeout ${{ env.HEALTH_CHECK_TIMEOUT }} python -m src.mirror_watcher_ai.cli health > artifacts/health_check.json 2>&1
          HEALTH_EXIT_CODE=$?
          
          # Handle timeout or other errors
          if [ $HEALTH_EXIT_CODE -eq 124 ]; then
            echo "::warning::Health check timed out after ${{ env.HEALTH_CHECK_TIMEOUT }} seconds"
            echo "health-status=timeout" >> $GITHUB_OUTPUT
            echo '{"timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "overall_status": "timeout", "error": "Health check timed out"}' > artifacts/health_check.json
          elif [ $HEALTH_EXIT_CODE -eq 0 ]; then
            echo "health-status=healthy" >> $GITHUB_OUTPUT
            echo "✅ System health check passed"
          else
            echo "health-status=degraded" >> $GITHUB_OUTPUT
            echo "⚠️ System health check shows issues (exit code: ${HEALTH_EXIT_CODE})"
          fi
          
          # Display health summary safely
          if [ -f "artifacts/health_check.json" ]; then
            echo "🏥 Health Status Summary:"
            if command -v jq >/dev/null 2>&1; then
              cat artifacts/health_check.json | jq -r '.overall_status // "unknown"' || echo "unknown"
            else
              grep -o '"overall_status"[[:space:]]*:[[:space:]]*"[^"]*"' artifacts/health_check.json | cut -d'"' -f4 || echo "unknown"
            fi
          else
            echo "❌ Health check results not available"
          fi
          
          echo "exit-code=${HEALTH_EXIT_CODE}" >> $GITHUB_OUTPUT
          echo "::endgroup::"
      
      - name: 🔍 Execute Mirror Analysis
        id: analysis
        timeout-minutes: 32  # Based on ANALYSIS_TIMEOUT + buffer
        env:
          ANALYSIS_TYPE: ${{ github.event.inputs.analysis_type || 'full' }}
          TARGET_REPOSITORIES: ${{ github.event.inputs.target_repositories }}
        run: |
          echo "::group::Mirror Analysis Execution"
          
          # Generate unique analysis ID
          ANALYSIS_ID="github_$(date +%Y%m%d_%H%M%S)_${GITHUB_RUN_NUMBER}"
          echo "analysis-id=${ANALYSIS_ID}" >> $GITHUB_OUTPUT
          echo "🔍 Analysis ID: ${ANALYSIS_ID}"
          echo "📊 Analysis Type: ${ANALYSIS_TYPE}"
          
          # Create analysis command based on type with timeout
          ANALYSIS_CMD=""
          OUTPUT_FILE=""
          
          case "${ANALYSIS_TYPE}" in
            "full")
              echo "🔍 Executing full mirror analysis..."
              OUTPUT_FILE="artifacts/analysis_${ANALYSIS_ID}.json"
              ANALYSIS_CMD="python -m src.mirror_watcher_ai.cli analyze --output \"${OUTPUT_FILE}\""
              ;;
            "repositories_only")
              echo "📁 Executing repository scan..."
              OUTPUT_FILE="artifacts/scan_${ANALYSIS_ID}.json"
              if [ -n "${TARGET_REPOSITORIES}" ]; then
                IFS=',' read -ra REPOS <<< "${TARGET_REPOSITORIES}"
                ANALYSIS_CMD="python -m src.mirror_watcher_ai.cli scan --repositories \"${REPOS[@]}\" --output \"${OUTPUT_FILE}\""
              else
                ANALYSIS_CMD="python -m src.mirror_watcher_ai.cli scan --output \"${OUTPUT_FILE}\""
              fi
              ;;
            "security_focus")
              echo "🔒 Executing security-focused analysis..."
              OUTPUT_FILE="artifacts/security_${ANALYSIS_ID}.json"
              ANALYSIS_CMD="python -m src.mirror_watcher_ai.cli analyze --security-focus --output \"${OUTPUT_FILE}\""
              ;;
            "health_check")
              echo "🏥 Executing enhanced health check..."
              OUTPUT_FILE="artifacts/health_${ANALYSIS_ID}.json"
              ANALYSIS_CMD="python -m src.mirror_watcher_ai.cli health --detailed --output \"${OUTPUT_FILE}\""
              ;;
            *)
              echo "::error::Unknown analysis type: ${ANALYSIS_TYPE}"
              echo "status=failed" >> $GITHUB_OUTPUT
              exit 1
              ;;
          esac
          
          # Execute analysis with timeout and retry logic
          RETRY_COUNT=0
          MAX_RETRIES=2  # Reduced retries for analysis
          ANALYSIS_SUCCESS=false
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$ANALYSIS_SUCCESS" = "false" ]; do
            echo "🚀 Starting analysis (attempt $((RETRY_COUNT + 1))/${MAX_RETRIES})"
            
            # Run with timeout
            if timeout ${{ env.ANALYSIS_TIMEOUT }} bash -c "${ANALYSIS_CMD}"; then
              ANALYSIS_EXIT_CODE=$?
              if [ $ANALYSIS_EXIT_CODE -eq 0 ]; then
                ANALYSIS_SUCCESS=true
                echo "✅ Analysis completed successfully"
                break
              else
                echo "⚠️ Analysis failed with exit code ${ANALYSIS_EXIT_CODE}"
              fi
            else
              TIMEOUT_EXIT_CODE=$?
              if [ $TIMEOUT_EXIT_CODE -eq 124 ]; then
                echo "::warning::Analysis timed out after ${{ env.ANALYSIS_TIMEOUT }} seconds"
                echo "timeout-occurred=true" >> $GITHUB_OUTPUT
              else
                echo "::error::Analysis command failed to execute"
              fi
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            if [ $RETRY_COUNT -lt $MAX_RETRIES ] && [ "$ANALYSIS_SUCCESS" = "false" ]; then
              echo "⏳ Waiting ${{ env.RETRY_DELAY }} seconds before retry..."
              sleep ${{ env.RETRY_DELAY }}
            fi
          done
          
          # Set final status
          if [ "$ANALYSIS_SUCCESS" = "true" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            
            # Extract metrics from analysis results safely
            if [ -f "${OUTPUT_FILE}" ]; then
              echo "📊 Extracting analysis metrics..."
              
              # Use safer extraction methods
              if command -v jq >/dev/null 2>&1; then
                REPOS_COUNT=$(cat "${OUTPUT_FILE}" | jq -r '.analysis_summary.repositories_analyzed // 0' 2>/dev/null || echo "0")
                HEALTH_SCORE=$(cat "${OUTPUT_FILE}" | jq -r '.analysis_summary.average_health_score // 0' 2>/dev/null || echo "0")
                SECURITY_STATUS=$(cat "${OUTPUT_FILE}" | jq -r '.security_assessment.overall_security_status // "unknown"' 2>/dev/null || echo "unknown")
              else
                # Fallback parsing without jq
                REPOS_COUNT=$(grep -o '"repositories_analyzed"[[:space:]]*:[[:space:]]*[0-9]*' "${OUTPUT_FILE}" | grep -o '[0-9]*$' || echo "0")
                HEALTH_SCORE=$(grep -o '"average_health_score"[[:space:]]*:[[:space:]]*[0-9]*' "${OUTPUT_FILE}" | grep -o '[0-9]*$' || echo "0")
                SECURITY_STATUS=$(grep -o '"overall_security_status"[[:space:]]*:[[:space:]]*"[^"]*"' "${OUTPUT_FILE}" | cut -d'"' -f4 || echo "unknown")
              fi
              
              echo "repositories-count=${REPOS_COUNT}" >> $GITHUB_OUTPUT
              echo "health-score=${HEALTH_SCORE}" >> $GITHUB_OUTPUT
              echo "security-status=${SECURITY_STATUS}" >> $GITHUB_OUTPUT
              
              echo "📈 Analysis Summary:"
              echo "   Repositories: ${REPOS_COUNT}"
              echo "   Health Score: ${HEALTH_SCORE}%"
              echo "   Security: ${SECURITY_STATUS}"
            else
              echo "::warning::Analysis output file not found: ${OUTPUT_FILE}"
              echo "repositories-count=0" >> $GITHUB_OUTPUT
              echo "health-score=0" >> $GITHUB_OUTPUT
              echo "security-status=unknown" >> $GITHUB_OUTPUT
            fi
          else
            echo "status=failed" >> $GITHUB_OUTPUT
            echo "repositories-count=0" >> $GITHUB_OUTPUT
            echo "health-score=0" >> $GITHUB_OUTPUT
            echo "security-status=failed" >> $GITHUB_OUTPUT
            echo "::error::❌ Analysis failed after ${MAX_RETRIES} attempts"
            # Don't exit here to allow cleanup steps to run
          fi
          
          echo "retry-count=${RETRY_COUNT}" >> $GITHUB_OUTPUT
          echo "output-file=${OUTPUT_FILE}" >> $GITHUB_OUTPUT
          echo "::endgroup::"
      
      - name: 🔒 ShadowScrolls Attestation
        id: attestation
        if: steps.analysis.outputs.status == 'success'
        timeout-minutes: 5
        run: |
          echo "::group::ShadowScrolls Attestation"
          
          ANALYSIS_ID="${{ steps.analysis.outputs.analysis-id }}"
          OUTPUT_FILE="${{ steps.analysis.outputs.output-file }}"
          
          # Create attestation for analysis results
          if [ -f "${OUTPUT_FILE}" ]; then
            echo "🔒 Creating ShadowScrolls attestation for ${OUTPUT_FILE}..."
            
            # Attempt attestation with timeout and error handling
            ATTESTATION_CMD="python -m src.mirror_watcher_ai.cli attest --data \"${OUTPUT_FILE}\" --output \"artifacts/attestation_${ANALYSIS_ID}.json\""
            
            if timeout 240 bash -c "${ATTESTATION_CMD}"; then  # 4 minute timeout for attestation
              ATTEST_EXIT_CODE=$?
              
              if [ $ATTEST_EXIT_CODE -eq 0 ]; then
                echo "attestation-status=success" >> $GITHUB_OUTPUT
                echo "✅ ShadowScrolls attestation created successfully"
                
                # Extract attestation metadata safely
                ATTESTATION_FILE="artifacts/attestation_${ANALYSIS_ID}.json"
                if [ -f "${ATTESTATION_FILE}" ]; then
                  if command -v jq >/dev/null 2>&1; then
                    SCROLL_ID=$(cat "${ATTESTATION_FILE}" | jq -r '.scroll_id // "unknown"' 2>/dev/null || echo "unknown")
                  else
                    SCROLL_ID=$(grep -o '"scroll_id"[[:space:]]*:[[:space:]]*"[^"]*"' "${ATTESTATION_FILE}" | cut -d'"' -f4 || echo "unknown")
                  fi
                  
                  echo "scroll-id=${SCROLL_ID}" >> $GITHUB_OUTPUT
                  echo "📜 Scroll ID: ${SCROLL_ID}"
                  echo "attestation-file=artifacts/attestation_${ANALYSIS_ID}.json" >> $GITHUB_OUTPUT
                else
                  echo "::warning::Attestation file not found despite successful creation"
                  echo "scroll-id=unknown" >> $GITHUB_OUTPUT
                fi
              else
                echo "attestation-status=failed" >> $GITHUB_OUTPUT
                echo "scroll-id=none" >> $GITHUB_OUTPUT
                echo "::warning::ShadowScrolls attestation command failed (exit code: ${ATTEST_EXIT_CODE})"
              fi
            else
              TIMEOUT_EXIT_CODE=$?
              if [ $TIMEOUT_EXIT_CODE -eq 124 ]; then
                echo "attestation-status=timeout" >> $GITHUB_OUTPUT
                echo "scroll-id=none" >> $GITHUB_OUTPUT
                echo "::warning::ShadowScrolls attestation timed out"
              else
                echo "attestation-status=error" >> $GITHUB_OUTPUT
                echo "scroll-id=none" >> $GITHUB_OUTPUT
                echo "::error::ShadowScrolls attestation command error"
              fi
            fi
          else
            echo "attestation-status=no-data" >> $GITHUB_OUTPUT
            echo "scroll-id=none" >> $GITHUB_OUTPUT
            echo "::warning::No analysis data available for attestation"
          fi
          
          echo "::endgroup::"
      
      - name: 🔄 Triune Ecosystem Sync
        id: ecosystem-sync
        if: steps.analysis.outputs.status == 'success'
        timeout-minutes: 16  # Based on SYNC_TIMEOUT + buffer
        env:
          FORCE_SYNC: ${{ github.event.inputs.force_sync || 'false' }}
        run: |
          echo "::group::Triune Ecosystem Synchronization"
          
          # Prepare sync command with appropriate flags
          if [ "${FORCE_SYNC}" == "true" ]; then
            echo "🔄 Force synchronization enabled"
            SYNC_CMD="python -m src.mirror_watcher_ai.cli sync --force"
          else
            echo "🔄 Regular synchronization"
            SYNC_CMD="python -m src.mirror_watcher_ai.cli sync"
          fi
          
          # Execute sync with timeout and error handling
          SYNC_OUTPUT_FILE="artifacts/ecosystem_sync.json"
          
          if timeout ${{ env.SYNC_TIMEOUT }} bash -c "${SYNC_CMD} > ${SYNC_OUTPUT_FILE} 2>&1"; then
            SYNC_EXIT_CODE=$?
            
            if [ $SYNC_EXIT_CODE -eq 0 ]; then
              echo "sync-status=success" >> $GITHUB_OUTPUT
              echo "✅ Ecosystem synchronization completed successfully"
              
              # Display sync summary safely
              if [ -f "${SYNC_OUTPUT_FILE}" ]; then
                echo "📊 Sync Summary:"
                if command -v jq >/dev/null 2>&1; then
                  cat "${SYNC_OUTPUT_FILE}" | jq '.summary // {}' 2>/dev/null || echo "Summary not available in JSON format"
                else
                  echo "Sync completed - detailed summary in artifacts"
                fi
                
                # Extract key metrics
                if command -v jq >/dev/null 2>&1; then
                  SERVICES_SYNCED=$(cat "${SYNC_OUTPUT_FILE}" | jq -r '.summary.services_synced // 0' 2>/dev/null || echo "0")
                  SYNC_ERRORS=$(cat "${SYNC_OUTPUT_FILE}" | jq -r '.summary.errors // 0' 2>/dev/null || echo "0")
                  echo "services-synced=${SERVICES_SYNCED}" >> $GITHUB_OUTPUT
                  echo "sync-errors=${SYNC_ERRORS}" >> $GITHUB_OUTPUT
                  echo "   Services synced: ${SERVICES_SYNCED}"
                  echo "   Sync errors: ${SYNC_ERRORS}"
                fi
              fi
            else
              echo "sync-status=failed" >> $GITHUB_OUTPUT
              echo "services-synced=0" >> $GITHUB_OUTPUT
              echo "sync-errors=1" >> $GITHUB_OUTPUT
              echo "::warning::Ecosystem synchronization failed (exit code: ${SYNC_EXIT_CODE})"
            fi
          else
            TIMEOUT_EXIT_CODE=$?
            if [ $TIMEOUT_EXIT_CODE -eq 124 ]; then
              echo "sync-status=timeout" >> $GITHUB_OUTPUT
              echo "services-synced=0" >> $GITHUB_OUTPUT
              echo "sync-errors=1" >> $GITHUB_OUTPUT
              echo "::warning::Ecosystem synchronization timed out after ${{ env.SYNC_TIMEOUT }} seconds"
              echo '{"timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'", "status": "timeout", "error": "Sync operation timed out"}' > "${SYNC_OUTPUT_FILE}"
            else
              echo "sync-status=error" >> $GITHUB_OUTPUT
              echo "services-synced=0" >> $GITHUB_OUTPUT
              echo "sync-errors=1" >> $GITHUB_OUTPUT
              echo "::error::Ecosystem synchronization command error"
            fi
          fi
          
          echo "::endgroup::"
      
      - name: 🚨 Error Handler & Status Collection
        id: error-handler
        if: always()
        timeout-minutes: 2
        run: |
          echo "::group::Error Handler & Status Collection"
          
          # Collect all step statuses
          ENV_VALIDATION="${{ steps.env-validation.outputs.validation-status }}"
          DEPS_INSTALL="${{ steps.install-deps.outputs.install-status }}"
          HEALTH_CHECK="${{ steps.health-check.outputs.health-status }}"
          ANALYSIS_STATUS="${{ steps.analysis.outputs.status }}"
          ATTESTATION_STATUS="${{ steps.attestation.outputs.attestation-status }}"
          SYNC_STATUS="${{ steps.ecosystem-sync.outputs.sync-status }}"
          
          echo "📊 Step Status Summary:"
          echo "   Environment Validation: ${ENV_VALIDATION:-unknown}"
          echo "   Dependencies: ${DEPS_INSTALL:-unknown}"
          echo "   Health Check: ${HEALTH_CHECK:-unknown}"
          echo "   Analysis: ${ANALYSIS_STATUS:-unknown}"
          echo "   Attestation: ${ATTESTATION_STATUS:-unknown}"
          echo "   Ecosystem Sync: ${SYNC_STATUS:-unknown}"
          
          # Determine overall workflow status
          FAILED_STEPS=0
          WARNING_STEPS=0
          
          # Count failures and warnings
          for status in "${ENV_VALIDATION}" "${DEPS_INSTALL}" "${HEALTH_CHECK}" "${ANALYSIS_STATUS}" "${ATTESTATION_STATUS}" "${SYNC_STATUS}"; do
            case "${status}" in
              "failed"|"error"|"timeout") FAILED_STEPS=$((FAILED_STEPS + 1)) ;;
              "warnings"|"degraded") WARNING_STEPS=$((WARNING_STEPS + 1)) ;;
            esac
          done
          
          # Set overall status
          if [ $FAILED_STEPS -gt 0 ]; then
            OVERALL_STATUS="failed"
            SEVERITY="error"
          elif [ $WARNING_STEPS -gt 0 ]; then
            OVERALL_STATUS="warning"
            SEVERITY="warning"
          else
            OVERALL_STATUS="success"
            SEVERITY="info"
          fi
          
          echo "overall-status=${OVERALL_STATUS}" >> $GITHUB_OUTPUT
          echo "failed-steps=${FAILED_STEPS}" >> $GITHUB_OUTPUT
          echo "warning-steps=${WARNING_STEPS}" >> $GITHUB_OUTPUT
          echo "severity=${SEVERITY}" >> $GITHUB_OUTPUT
          
          # Create error summary
          ERROR_SUMMARY="{\"overall_status\": \"${OVERALL_STATUS}\", \"failed_steps\": ${FAILED_STEPS}, \"warning_steps\": ${WARNING_STEPS}, \"severity\": \"${SEVERITY}\"}"
          echo "error-summary=${ERROR_SUMMARY}" >> $GITHUB_OUTPUT
          
          echo "🎯 Overall Status: ${OVERALL_STATUS} (${FAILED_STEPS} failures, ${WARNING_STEPS} warnings)"
          
          # Log critical errors
          if [ $FAILED_STEPS -gt 2 ]; then
            echo "::error::🚨 Multiple critical failures detected! Workflow requires immediate attention."
          elif [ $FAILED_STEPS -gt 0 ]; then
            echo "::warning::⚠️ Some steps failed but workflow continued for cleanup."
          fi
          
          echo "::endgroup::"
      
      - name: 📊 Generate Reports
        id: reporting
        if: always()
        timeout-minutes: 3
        run: |
          echo "::group::Report Generation"
          
          ANALYSIS_ID="${{ steps.analysis.outputs.analysis-id }}"
          TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
          START_TIME="${{ steps.workflow-init.outputs.start-time }}"
          OVERALL_STATUS="${{ steps.error-handler.outputs.overall-status }}"
          
          # Calculate duration
          if [ -n "${START_TIME}" ]; then
            START_TIMESTAMP=$(date -d "${START_TIME}" +%s 2>/dev/null || echo "0")
            END_TIMESTAMP=$(date +%s)
            DURATION=$((END_TIMESTAMP - START_TIMESTAMP))
            DURATION_FORMATTED="${DURATION}s"
          else
            DURATION_FORMATTED="unknown"
          fi
          
          # Create comprehensive execution summary
          cat > artifacts/execution_summary.json << EOF
          {
            "execution_id": "${ANALYSIS_ID}",
            "timestamp": "${TIMESTAMP}",
            "start_time": "${START_TIME}",
            "duration": "${DURATION_FORMATTED}",
            "trigger": "${{ github.event_name }}",
            "workflow_run_id": "${{ github.run_id }}",
            "workflow_run_number": "${{ github.run_number }}",
            "overall_status": "${OVERALL_STATUS}",
            "environment": {
              "validation_status": "${{ steps.env-validation.outputs.validation-status }}",
              "validation_errors": "${{ steps.env-validation.outputs.validation-errors }}"
            },
            "dependencies": {
              "install_status": "${{ steps.install-deps.outputs.install-status }}"
            },
            "analysis": {
              "status": "${{ steps.analysis.outputs.status }}",
              "type": "${{ github.event.inputs.analysis_type || 'full' }}",
              "repositories_analyzed": "${{ steps.analysis.outputs.repositories-count }}",
              "health_score": "${{ steps.analysis.outputs.health-score }}",
              "security_status": "${{ steps.analysis.outputs.security-status }}",
              "retry_count": "${{ steps.analysis.outputs.retry-count }}",
              "timeout_occurred": "${{ steps.analysis.outputs.timeout-occurred }}"
            },
            "attestation": {
              "status": "${{ steps.attestation.outputs.attestation-status }}",
              "scroll_id": "${{ steps.attestation.outputs.scroll-id }}"
            },
            "ecosystem_sync": {
              "status": "${{ steps.ecosystem-sync.outputs.sync-status }}",
              "services_synced": "${{ steps.ecosystem-sync.outputs.services-synced }}",
              "sync_errors": "${{ steps.ecosystem-sync.outputs.sync-errors }}"
            },
            "system_health": {
              "status": "${{ steps.health-check.outputs.health-status }}",
              "exit_code": "${{ steps.health-check.outputs.exit-code }}"
            },
            "error_summary": ${{ steps.error-handler.outputs.error-summary }}
          }
          EOF
          
          # Create enhanced human-readable report
          cat > artifacts/execution_report.md << EOF
          # 🔍 MirrorWatcherAI Execution Report
          
          **Execution ID:** \`${ANALYSIS_ID}\`  
          **Timestamp:** ${TIMESTAMP}  
          **Duration:** ${DURATION_FORMATTED}  
          **Trigger:** ${{ github.event_name }}  
          **Workflow:** [${{ github.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})  
          **Overall Status:** **${OVERALL_STATUS}** ⚠️
          
          ## 📊 Analysis Results
          
          - **Status:** ${{ steps.analysis.outputs.status }}
          - **Type:** ${{ github.event.inputs.analysis_type || 'full' }}
          - **Repositories Analyzed:** ${{ steps.analysis.outputs.repositories-count }}
          - **Average Health Score:** ${{ steps.analysis.outputs.health-score }}%
          - **Security Status:** ${{ steps.analysis.outputs.security-status }}
          - **Retry Attempts:** ${{ steps.analysis.outputs.retry-count }}
          
          ## 🔒 Attestation
          
          - **Status:** ${{ steps.attestation.outputs.attestation-status }}
          - **Scroll ID:** ${{ steps.attestation.outputs.scroll-id }}
          
          ## 🔄 Ecosystem Sync
          
          - **Status:** ${{ steps.ecosystem-sync.outputs.sync-status }}
          - **Services Synced:** ${{ steps.ecosystem-sync.outputs.services-synced }}
          - **Sync Errors:** ${{ steps.ecosystem-sync.outputs.sync-errors }}
          
          ## 🏥 System Health
          
          - **Status:** ${{ steps.health-check.outputs.health-status }}
          - **Exit Code:** ${{ steps.health-check.outputs.exit-code }}
          
          ## 🌍 Environment
          
          - **Validation:** ${{ steps.env-validation.outputs.validation-status }}
          - **Dependencies:** ${{ steps.install-deps.outputs.install-status }}
          - **Validation Errors:** ${{ steps.env-validation.outputs.validation-errors }}
          
          ## 📈 Performance Metrics
          
          - **Failed Steps:** ${{ steps.error-handler.outputs.failed-steps }}
          - **Warning Steps:** ${{ steps.error-handler.outputs.warning-steps }}
          - **Severity Level:** ${{ steps.error-handler.outputs.severity }}
          
          ---
          
          *Generated by MirrorWatcherAI v1.0.0 - Enhanced Production Workflow*
          EOF
          
          echo "✅ Reports generated successfully"
          echo "📄 Summary: artifacts/execution_summary.json"
          echo "📖 Report: artifacts/execution_report.md"
          echo "::endgroup::"
      
      - name: 🔚 Workflow Finalization
        id: workflow-finalize
        if: always()
        run: |
          echo "::group::Workflow Finalization"
          END_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "end-time=${END_TIME}" >> $GITHUB_OUTPUT
          echo "🏁 MirrorWatcherAI workflow completed at ${END_TIME}"
          echo "📊 Final Status: ${{ steps.error-handler.outputs.overall-status }}"
          echo "::endgroup::"
      
      - name: 📤 Upload Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mirror-analysis-${{ steps.analysis.outputs.analysis-id }}
          path: |
            artifacts/
            logs/
            .shadowscrolls/
          retention-days: ${{ env.ARTIFACT_RETENTION_DAYS }}
          compression-level: 6
      
      - name: 💬 Update Status Badge
        if: always()
        run: |
          echo "::group::Status Badge Update"
          
          # Determine badge status
          if [ "${{ steps.analysis.outputs.status }}" == "success" ]; then
            BADGE_STATUS="passing"
            BADGE_COLOR="brightgreen"
          else
            BADGE_STATUS="failing"
            BADGE_COLOR="red"
          fi
          
          # Create status badge data
          cat > artifacts/status_badge.json << EOF
          {
            "schemaVersion": 1,
            "label": "Mirror Analysis",
            "message": "${BADGE_STATUS}",
            "color": "${BADGE_COLOR}",
            "namedLogo": "github",
            "logoColor": "white"
          }
          EOF
          
          echo "📛 Status badge updated: ${BADGE_STATUS}"
          echo "::endgroup::"

  notification:
    name: 📢 Notifications & Alerts
    runs-on: ubuntu-latest
    needs: mirror-analysis
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: 🚀 Checkout Repository
        uses: actions/checkout@v4
        timeout-minutes: 2
      
      - name: 📊 Analysis Summary
        id: summary
        env:
          ANALYSIS_STATUS: ${{ needs.mirror-analysis.outputs.execution-status }}
          REPOSITORIES_ANALYZED: ${{ needs.mirror-analysis.outputs.repositories-analyzed }}
          HEALTH_SCORE: ${{ needs.mirror-analysis.outputs.health-score }}
          SECURITY_STATUS: ${{ needs.mirror-analysis.outputs.security-status }}
          ERROR_DETAILS: ${{ needs.mirror-analysis.outputs.error-details }}
          START_TIME: ${{ needs.mirror-analysis.outputs.start-time }}
          END_TIME: ${{ needs.mirror-analysis.outputs.end-time }}
        run: |
          echo "::group::Analysis Summary"
          
          # Calculate duration if times are available
          if [ -n "${START_TIME}" ] && [ -n "${END_TIME}" ]; then
            START_TIMESTAMP=$(date -d "${START_TIME}" +%s 2>/dev/null || echo "0")
            END_TIMESTAMP=$(date -d "${END_TIME}" +%s 2>/dev/null || echo "0")
            if [ $START_TIMESTAMP -gt 0 ] && [ $END_TIMESTAMP -gt 0 ]; then
              DURATION=$((END_TIMESTAMP - START_TIMESTAMP))
              DURATION_FORMATTED="${DURATION}s"
            else
              DURATION_FORMATTED="unknown"
            fi
          else
            DURATION_FORMATTED="unknown"
          fi
          
          echo "🔍 MirrorWatcherAI Daily Analysis Complete"
          echo ""
          echo "📊 Results Summary:"
          echo "   Status: ${ANALYSIS_STATUS}"
          echo "   Duration: ${DURATION_FORMATTED}"
          echo "   Repositories: ${REPOSITORIES_ANALYZED}"
          echo "   Health Score: ${HEALTH_SCORE}%"
          echo "   Security: ${SECURITY_STATUS}"
          echo ""
          echo "🔗 Full Report: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          # Set summary for other steps
          echo "duration=${DURATION_FORMATTED}" >> $GITHUB_OUTPUT
          
          echo "::endgroup::"
      
      - name: 🚨 Critical Alert Check
        id: critical-alert
        if: needs.mirror-analysis.outputs.execution-status == 'failed' || needs.mirror-analysis.outputs.health-score < '60' || needs.mirror-analysis.outputs.security-status == 'critical'
        run: |
          echo "::group::Critical Alert Processing"
          
          ALERT_REASONS=""
          ALERT_COUNT=0
          
          # Check failure conditions
          if [ "${{ needs.mirror-analysis.outputs.execution-status }}" == "failed" ]; then
            ALERT_REASONS="${ALERT_REASONS}- Workflow execution failed\n"
            ALERT_COUNT=$((ALERT_COUNT + 1))
          fi
          
          if [ "${{ needs.mirror-analysis.outputs.health-score }}" -lt "60" 2>/dev/null ]; then
            ALERT_REASONS="${ALERT_REASONS}- Health score below threshold (60%): ${{ needs.mirror-analysis.outputs.health-score }}%\n"
            ALERT_COUNT=$((ALERT_COUNT + 1))
          fi
          
          if [ "${{ needs.mirror-analysis.outputs.security-status }}" == "critical" ]; then
            ALERT_REASONS="${ALERT_REASONS}- Critical security status detected\n"
            ALERT_COUNT=$((ALERT_COUNT + 1))
          fi
          
          echo "::error::🚨 CRITICAL ALERT: MirrorWatcherAI requires immediate attention!"
          echo "::error::Alert Count: ${ALERT_COUNT}"
          echo "::error::Execution Status: ${{ needs.mirror-analysis.outputs.execution-status }}"
          echo "::error::Health Score: ${{ needs.mirror-analysis.outputs.health-score }}%"
          echo "::error::Security Status: ${{ needs.mirror-analysis.outputs.security-status }}"
          echo ""
          echo "::error::Alert Reasons:"
          echo -e "${ALERT_REASONS}"
          echo ""
          echo "::error::Action Required: Check logs and resolve issues immediately"
          echo "::error::Workflow URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          # Create alert file for potential external processing
          cat > /tmp/critical_alert.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "alert_level": "critical",
            "workflow_run": "${{ github.run_id }}",
            "execution_status": "${{ needs.mirror-analysis.outputs.execution-status }}",
            "health_score": "${{ needs.mirror-analysis.outputs.health-score }}",
            "security_status": "${{ needs.mirror-analysis.outputs.security-status }}",
            "alert_count": ${ALERT_COUNT},
            "repository": "${{ github.repository }}",
            "workflow_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }
          EOF
          
          echo "alert-created=true" >> $GITHUB_OUTPUT
          echo "alert-count=${ALERT_COUNT}" >> $GITHUB_OUTPUT
          
          echo "::endgroup::"
      
      - name: ⚠️ Warning Alert Check
        id: warning-alert
        if: steps.critical-alert.outputs.alert-created != 'true' && (needs.mirror-analysis.outputs.health-score < '80' || needs.mirror-analysis.outputs.security-status == 'degraded')
        run: |
          echo "::group::Warning Alert Processing"
          
          echo "::warning::⚠️ MirrorWatcherAI Warning: Performance degradation detected"
          
          WARNING_REASONS=""
          if [ "${{ needs.mirror-analysis.outputs.health-score }}" -lt "80" 2>/dev/null ]; then
            WARNING_REASONS="${WARNING_REASONS}- Health score below optimal (80%): ${{ needs.mirror-analysis.outputs.health-score }}%\n"
          fi
          
          if [ "${{ needs.mirror-analysis.outputs.security-status }}" == "degraded" ]; then
            WARNING_REASONS="${WARNING_REASONS}- Security status shows degradation\n"
          fi
          
          echo "::warning::Warning Reasons:"
          echo -e "${WARNING_REASONS}"
          echo "::warning::Recommendation: Monitor system and consider maintenance"
          
          echo "warning-created=true" >> $GITHUB_OUTPUT
          
          echo "::endgroup::"
      
      - name: ✅ Success Notification
        if: needs.mirror-analysis.outputs.execution-status == 'success' && needs.mirror-analysis.outputs.health-score >= '80' && steps.critical-alert.outputs.alert-created != 'true' && steps.warning-alert.outputs.warning-created != 'true'
        run: |
          echo "::group::Success Notification"
          
          echo "✅ MirrorWatcherAI analysis completed successfully!"
          echo "🎯 All systems operating within normal parameters"
          echo "📈 Health Score: ${{ needs.mirror-analysis.outputs.health-score }}%"
          echo "🔒 Security Status: ${{ needs.mirror-analysis.outputs.security-status }}"
          echo "📊 Repositories Analyzed: ${{ needs.mirror-analysis.outputs.repositories-analyzed }}"
          echo "⏱️ Duration: ${{ steps.summary.outputs.duration }}"
          echo ""
          echo "🔗 View detailed report: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          # Create success summary
          echo "## ✅ MirrorWatcherAI Success Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ✅ Success" >> $GITHUB_STEP_SUMMARY
          echo "- **Health Score**: ${{ needs.mirror-analysis.outputs.health-score }}%" >> $GITHUB_STEP_SUMMARY
          echo "- **Security**: ${{ needs.mirror-analysis.outputs.security-status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Repositories**: ${{ needs.mirror-analysis.outputs.repositories-analyzed }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Duration**: ${{ steps.summary.outputs.duration }}" >> $GITHUB_STEP_SUMMARY
          
          echo "::endgroup::"
      
      - name: 📧 Notification Summary
        if: always()
        run: |
          echo "::group::Notification Summary"
          
          # Determine notification type sent
          if [ "${{ steps.critical-alert.outputs.alert-created }}" == "true" ]; then
            NOTIFICATION_TYPE="critical_alert"
            NOTIFICATION_COUNT="${{ steps.critical-alert.outputs.alert-count }}"
          elif [ "${{ steps.warning-alert.outputs.warning-created }}" == "true" ]; then
            NOTIFICATION_TYPE="warning"
            NOTIFICATION_COUNT="1"
          elif [ "${{ needs.mirror-analysis.outputs.execution-status }}" == "success" ]; then
            NOTIFICATION_TYPE="success"
            NOTIFICATION_COUNT="0"
          else
            NOTIFICATION_TYPE="unknown"
            NOTIFICATION_COUNT="0"
          fi
          
          echo "📧 Notification Summary:"
          echo "   Type: ${NOTIFICATION_TYPE}"
          echo "   Alert Count: ${NOTIFICATION_COUNT}"
          echo "   Execution Status: ${{ needs.mirror-analysis.outputs.execution-status }}"
          echo "   Health Score: ${{ needs.mirror-analysis.outputs.health-score }}%"
          
          # Add to workflow summary
          echo "## 📢 Notification Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Notification Type**: ${NOTIFICATION_TYPE}" >> $GITHUB_STEP_SUMMARY
          echo "- **Alert Count**: ${NOTIFICATION_COUNT}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow Status**: ${{ needs.mirror-analysis.outputs.execution-status }}" >> $GITHUB_STEP_SUMMARY
          
          echo "::endgroup::"

  cleanup:
    name: 🧹 Cleanup & Maintenance
    runs-on: ubuntu-latest
    needs: [mirror-analysis, notification]
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: 🚀 Checkout Repository
        uses: actions/checkout@v4
        timeout-minutes: 2
      
      - name: 🧹 Artifact Cleanup
        id: cleanup
        timeout-minutes: 2
        run: |
          echo "::group::Artifact Cleanup"
          
          # Calculate cleanup metrics
          CURRENT_ARTIFACTS=$(find . -type f -name "*.json" -o -name "*.log" -o -name "*.md" | wc -l)
          DISK_USAGE=$(du -sh . 2>/dev/null | cut -f1 || echo "unknown")
          
          echo "📊 Pre-cleanup metrics:"
          echo "   Current artifacts: ${CURRENT_ARTIFACTS}"
          echo "   Disk usage: ${DISK_USAGE}"
          
          # Cleanup temporary files (but preserve artifacts for upload)
          if [ -d "/tmp" ]; then
            find /tmp -name "mirror_watcher*" -mtime +1 -delete 2>/dev/null || true
            find /tmp -name "*.tmp" -mtime +1 -delete 2>/dev/null || true
          fi
          
          # Cleanup old logs if they exist locally
          if [ -d "logs" ]; then
            find logs -name "*.log" -mtime +7 -delete 2>/dev/null || true
          fi
          
          echo "✅ Local cleanup completed"
          echo "📅 Artifacts will be retained for ${{ env.ARTIFACT_RETENTION_DAYS }} days by GitHub"
          echo "🗂️ Cleanup relies on GitHub's built-in retention policy"
          
          # Set cleanup status
          echo "cleanup-status=completed" >> $GITHUB_OUTPUT
          echo "artifacts-count=${CURRENT_ARTIFACTS}" >> $GITHUB_OUTPUT
          echo "disk-usage=${DISK_USAGE}" >> $GITHUB_OUTPUT
          
          echo "::endgroup::"
      
      - name: 📈 Metrics Collection
        id: metrics
        timeout-minutes: 2
        run: |
          echo "::group::Metrics Collection"
          
          # Collect comprehensive execution metrics
          EXECUTION_TIME=$(date -u)
          WORKFLOW_DURATION="Calculated by GitHub Actions"
          ANALYSIS_STATUS="${{ needs.mirror-analysis.outputs.execution-status }}"
          REPOSITORIES_ANALYZED="${{ needs.mirror-analysis.outputs.repositories-analyzed }}"
          HEALTH_SCORE="${{ needs.mirror-analysis.outputs.health-score }}"
          
          echo "📊 Execution Metrics Collection:"
          echo "   Completion time: ${EXECUTION_TIME}"
          echo "   Workflow duration: ${WORKFLOW_DURATION}"
          echo "   Analysis status: ${ANALYSIS_STATUS}"
          echo "   Repositories analyzed: ${REPOSITORIES_ANALYZED}"
          echo "   Health score: ${HEALTH_SCORE}%"
          echo "   Artifacts generated: ${{ steps.cleanup.outputs.artifacts-count }}"
          echo "   Disk usage: ${{ steps.cleanup.outputs.disk-usage }}"
          
          # Create metrics summary
          cat > /tmp/workflow_metrics.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "workflow_run_id": "${{ github.run_id }}",
            "workflow_run_number": "${{ github.run_number }}",
            "execution_status": "${ANALYSIS_STATUS}",
            "repositories_analyzed": "${REPOSITORIES_ANALYZED}",
            "health_score": "${HEALTH_SCORE}",
            "artifacts_count": "${{ steps.cleanup.outputs.artifacts-count }}",
            "disk_usage": "${{ steps.cleanup.outputs.disk-usage }}",
            "retention_days": "${{ env.ARTIFACT_RETENTION_DAYS }}",
            "trigger_event": "${{ github.event_name }}",
            "repository": "${{ github.repository }}"
          }
          EOF
          
          # These metrics would typically be sent to monitoring systems
          # For now, they're logged for manual review
          echo "📈 Metrics collected successfully"
          echo "💾 Metrics saved to temporary storage"
          
          echo "metrics-collected=true" >> $GITHUB_OUTPUT
          
          echo "::endgroup::"
      
      - name: 🔍 Health Assessment
        id: health-assessment
        timeout-minutes: 1
        run: |
          echo "::group::Health Assessment"
          
          # Assess overall workflow health
          ANALYSIS_STATUS="${{ needs.mirror-analysis.outputs.execution-status }}"
          NOTIFICATION_STATUS="completed"  # Notification job completed if we're here
          CLEANUP_STATUS="${{ steps.cleanup.outputs.cleanup-status }}"
          
          # Determine overall health
          if [ "${ANALYSIS_STATUS}" == "success" ] && [ "${CLEANUP_STATUS}" == "completed" ]; then
            WORKFLOW_HEALTH="healthy"
            HEALTH_SCORE="100"
          elif [ "${ANALYSIS_STATUS}" == "success" ]; then
            WORKFLOW_HEALTH="mostly_healthy"
            HEALTH_SCORE="85"
          elif [ "${ANALYSIS_STATUS}" == "warning" ]; then
            WORKFLOW_HEALTH="degraded"
            HEALTH_SCORE="60"
          else
            WORKFLOW_HEALTH="unhealthy"
            HEALTH_SCORE="30"
          fi
          
          echo "🏥 Workflow Health Assessment:"
          echo "   Overall health: ${WORKFLOW_HEALTH}"
          echo "   Health score: ${HEALTH_SCORE}%"
          echo "   Analysis status: ${ANALYSIS_STATUS}"
          echo "   Notification status: ${NOTIFICATION_STATUS}"
          echo "   Cleanup status: ${CLEANUP_STATUS}"
          
          # Set recommendations based on health
          case "${WORKFLOW_HEALTH}" in
            "healthy")
              RECOMMENDATION="No action required. System operating optimally."
              ;;
            "mostly_healthy")
              RECOMMENDATION="Minor issues detected. Monitor next execution."
              ;;
            "degraded")
              RECOMMENDATION="Performance degradation. Review logs and consider maintenance."
              ;;
            "unhealthy")
              RECOMMENDATION="Critical issues detected. Immediate attention required."
              ;;
          esac
          
          echo "💡 Recommendation: ${RECOMMENDATION}"
          
          # Create health summary for workflow
          echo "## 🏥 Workflow Health Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Overall Health**: ${WORKFLOW_HEALTH} (${HEALTH_SCORE}%)" >> $GITHUB_STEP_SUMMARY
          echo "- **Analysis Status**: ${ANALYSIS_STATUS}" >> $GITHUB_STEP_SUMMARY
          echo "- **Cleanup Status**: ${CLEANUP_STATUS}" >> $GITHUB_STEP_SUMMARY
          echo "- **Recommendation**: ${RECOMMENDATION}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "*Next scheduled run: Tomorrow at 06:00 UTC*" >> $GITHUB_STEP_SUMMARY
          
          echo "health-assessment=${WORKFLOW_HEALTH}" >> $GITHUB_OUTPUT
          echo "health-score=${HEALTH_SCORE}" >> $GITHUB_OUTPUT
          echo "recommendation=${RECOMMENDATION}" >> $GITHUB_OUTPUT
          
          echo "::endgroup::"